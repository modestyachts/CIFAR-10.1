{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample new labeled images for the v4 dataset\n",
    "\n",
    "The script requires the following files from s3 in the `other_data` directory:\n",
    "* `tinyimage_large_dst_images_v4.json`\n",
    "* `tinyimage_large_dst_image_data_v4.pickle`\n",
    "* `cifar10_keywords.json`\n",
    "* `tinyimage_cifar10_distances_full.json`\n",
    "\n",
    "These files can be downloaded with `other_data/download.py --all`.\n",
    "\n",
    "Smaller files required that are checked in to the repo:\n",
    "* `blacklist_v4.json`\n",
    "* `keywords_v4.json`\n",
    "* `tinyimage_good_indices_subselected_v4.json`\n",
    "\n",
    "In addition, CIFAR-10 dataset should be downloaded in `other_data/cifar10`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import io\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "repo_root = os.path.join(os.getcwd(), '../code')\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import cifar10\n",
    "import utils\n",
    "\n",
    "cifar = cifar10.CIFAR10Data('../other_data/cifar10')\n",
    "cifar_labels = cifar.all_labels\n",
    "\n",
    "with open('../other_data/tinyimage_large_dst_images_v4.json', 'r') as f:\n",
    "    all_new_imgs = json.load(f)\n",
    "with open('../other_data/tinyimage_large_dst_image_data_v4.pickle', 'rb') as f:\n",
    "    img_data = pickle.load(f)\n",
    "with open('../other_data/tinyimage_good_indices_subselected_v4.json', 'r') as f:\n",
    "    tinyimage_good_indices = json.load(f)\n",
    "with open('../other_data/cifar10_keywords.json') as f:\n",
    "    cifar10_keywords = json.load(f)\n",
    "# Blacklist contains images that are near-duplicates in CIFAR-10\n",
    "with open('../other_data/blacklist_v4.json') as f:\n",
    "    blacklist = json.load(f)\n",
    "with open('../other_data/keywords_v4.json') as f:\n",
    "    new_keywords = json.load(f)\n",
    "\n",
    "distances = utils.load_v4_distances_to_cifar10()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 keywords\n",
    "\n",
    "Determine the number of images for each keyword in CIFAR-10. If the keyword belongs to multiple classes, we assign the keyword to the class where it occurrs most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip keywords for the associated list of classes.\n",
    "skip_keywords = {\n",
    "    'cruiser': [8],\n",
    "    'sound_truck' : [1], \n",
    "    'cavalier' : [1],\n",
    "    'domestic_dog' :[3],\n",
    "    'persian_cat' :[5],\n",
    "    'trailer_truck' : [1],\n",
    "    'frog' : [5],\n",
    "    'cab' :[9],\n",
    "    'tractor_trailer' : [8],\n",
    "    'pet' :[3],\n",
    "    'ambulance':[9, 8],\n",
    "    'gray' : [6],\n",
    "    'taxi' :[0],\n",
    "    'toy' : [2, 8, 3],\n",
    "    'automobile' : [8],\n",
    "    'sparrow' : [8],\n",
    "    'lark': [7],\n",
    "    'ford': [9]\n",
    "}\n",
    "\n",
    "# Build a map from keyword in CIFAR-10 to number of images in CIFAR-10\n",
    "cifar10_by_keyword = {}\n",
    "keyword_to_class = {}\n",
    "for ii, keyword_entries in enumerate(cifar10_keywords):\n",
    "    for entry in keyword_entries:\n",
    "        cur_keyword = entry['nn_keyword']\n",
    "        if cur_keyword in new_keywords:\n",
    "            if (cur_keyword in skip_keywords) and (cifar_labels[ii] in skip_keywords[cur_keyword]):\n",
    "                pass\n",
    "            else:\n",
    "                if cur_keyword in keyword_to_class:\n",
    "                    if not keyword_to_class[cur_keyword] == cifar_labels[ii]:\n",
    "                        print(cur_keyword)\n",
    "                        print(ii)\n",
    "                        print(keyword_to_class[cur_keyword])\n",
    "                        print(cifar_labels[ii])\n",
    "                    assert(keyword_to_class[cur_keyword] == cifar_labels[ii])\n",
    "                else:\n",
    "                    keyword_to_class[cur_keyword] = cifar_labels[ii]\n",
    "            if not cur_keyword in cifar10_by_keyword:\n",
    "                cifar10_by_keyword[cur_keyword] = 0\n",
    "            cifar10_by_keyword[cur_keyword] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2021 images\n"
     ]
    }
   ],
   "source": [
    "random.seed(670725112)\n",
    "new_data = np.empty((2021, 32,32,3), float)\n",
    "new_labels = np.empty(2021, int)\n",
    "\n",
    "# These keywords need 0 new images in the new dataset\n",
    "if 'sport_car' in new_keywords:\n",
    "    new_keywords.remove('sport_car')\n",
    "if 'door' in new_keywords:\n",
    "    new_keywords.remove('door')\n",
    "if 'ford' in new_keywords:\n",
    "    new_keywords.remove('ford')\n",
    "if 'opel' in new_keywords:\n",
    "    new_keywords.remove('opel')\n",
    "if 'sports_car' in new_keywords:\n",
    "    new_keywords.remove('sports_car')\n",
    "\n",
    "i = 0\n",
    "threshold = 1000\n",
    "tiny_image_map = []\n",
    "new_indices_dict = {}\n",
    "for keyword_name in new_keywords:\n",
    "    \n",
    "    cur_good_indices_1 = set(tinyimage_good_indices[keyword_name])\n",
    "    cur_good_indices_2 = []\n",
    "    cur_good_indices = []\n",
    "    \n",
    "    # Remove if the idx has an l2 nearest neighbor in CIFAR-10\n",
    "    for idx in cur_good_indices_1:\n",
    "        cur_distance = distances[idx][0][1]\n",
    "        if cur_distance > threshold:\n",
    "            cur_good_indices_2.append(idx)\n",
    "    \n",
    "    # Remove if the idx is on the blacklist \n",
    "    # (the blacklist mostly contains near duplicates with CIFAR-10)\n",
    "    for idx in cur_good_indices_2:\n",
    "        if idx not in blacklist:\n",
    "            cur_good_indices.append(idx)\n",
    "\n",
    "    num_cifar10_indices = cifar10_by_keyword[keyword_name]\n",
    "    new_imgs = all_new_imgs[keyword_name]\n",
    "    \n",
    "    num_selected_images = np.int(len(cur_good_indices))\n",
    "    if num_cifar10_indices / 30 < 0.5:\n",
    "        num_new_images = 0\n",
    "    else:\n",
    "        num_new_images = np.int(np.ceil(num_cifar10_indices/30))\n",
    "\n",
    "    if len(cur_good_indices) < num_new_images:\n",
    "        print(keyword_name)\n",
    "        print(num_new_images)\n",
    "        print(len(cur_good_indices))\n",
    "        continue\n",
    "    \n",
    "    # Sample the correct number of new indices\n",
    "    sampled_indices = random.sample(cur_good_indices, num_new_images)\n",
    "    new_indices_dict[keyword_name] = list(sampled_indices)\n",
    "\n",
    "    # Add the images and labels for this keyword\n",
    "    for idx in sampled_indices:\n",
    "        tiny_image_map.append(idx)\n",
    "        new_data[i] = img_data[idx]\n",
    "        new_labels[i] = np.int(keyword_to_class[keyword_name])\n",
    "        i = i+1\n",
    "\n",
    "print('Got {} images'.format(i))\n",
    "\n",
    "# Save a map from index in the new dataset to TinyImage index\n",
    "with open('../other_data/cifar10.1_v4_ti_indices_map.json', 'w') as f:\n",
    "    json.dump(tiny_image_map, f, indent=2)\n",
    "\n",
    "np.save('../datasets/cifar10.1_v4_data.npy', new_data.astype(np.uint8))\n",
    "np.save('../datasets/cifar10.1_v4_labels.npy', new_labels.astype(np.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
